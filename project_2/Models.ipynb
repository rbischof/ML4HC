{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Masking, Bidirectional, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTSNE(tsne_results, Y_test):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    label = Y_test\n",
    "    colors = ['blue', 'red']\n",
    "    plt.scatter(x=tsne_results[:,0], y=tsne_results[:,1], c=label, cmap=matplotlib.colors.ListedColormap(colors), s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_mean = np.asarray(pd.read_csv(\"data/diabetes/X_pca_mean.csv\", header=None))[:6000]\n",
    "X_val_pca_mean = np.asarray(pd.read_csv(\"data/diabetes/X_pca_mean.csv\", header=None))[6000:8000]\n",
    "X_test_pca_mean = np.asarray(pd.read_csv(\"data/diabetes/X_pca_mean.csv\", header=None))[8000:]\n",
    "\n",
    "X_lda_mean = np.asarray(pd.read_csv(\"data/diabetes/X_lda_mean.csv\", header=None))[:6000]\n",
    "X_val_lda_mean = np.asarray(pd.read_csv(\"data/diabetes/X_lda_mean.csv\", header=None))[6000:8000]\n",
    "X_test_lda_mean = np.asarray(pd.read_csv(\"data/diabetes/X_lda_mean.csv\", header=None))[8000:]\n",
    "\n",
    "X_pca_max = np.asarray(pd.read_csv(\"data/diabetes/X_pca_max.csv\", header=None))[:6000]\n",
    "X_val_pca_max = np.asarray(pd.read_csv(\"data/diabetes/X_pca_max.csv\", header=None))[6000:8000]\n",
    "X_test_pca_max = np.asarray(pd.read_csv(\"data/diabetes/X_pca_max.csv\", header=None))[8000:]\n",
    "\n",
    "X_lda_max = np.asarray(pd.read_csv(\"data/diabetes/X_lda_max.csv\", header=None))[:6000]\n",
    "X_val_lda_max = np.asarray(pd.read_csv(\"data/diabetes/X_lda_max.csv\", header=None))[6000:8000]\n",
    "X_test_lda_max = np.asarray(pd.read_csv(\"data/diabetes/X_lda_max.csv\", header=None))[8000:]\n",
    "\n",
    "X_pca_conc = np.asarray(pd.read_csv(\"data/diabetes/X_pca_conc.csv\", header=None))[:6000]\n",
    "X_val_pca_conc = np.asarray(pd.read_csv(\"data/diabetes/X_pca_conc.csv\", header=None))[6000:8000]\n",
    "X_test_pca_conc = np.asarray(pd.read_csv(\"data/diabetes/X_pca_conc.csv\", header=None))[8000:]\n",
    "\n",
    "X_lda_conc = np.asarray(pd.read_csv(\"data/diabetes/X_lda_conc.csv\", header=None))[:6000]\n",
    "X_val_lda_conc = np.asarray(pd.read_csv(\"data/diabetes/X_lda_conc.csv\", header=None))[6000:8000]\n",
    "X_test_lda_conc = np.asarray(pd.read_csv(\"data/diabetes/X_lda_conc.csv\", header=None))[8000:]\n",
    "\n",
    "Y = np.asarray(pd.read_csv(\"data/diabetes/Y.csv\", header=None)).reshape(-1).astype(int)\n",
    "Y_val = np.asarray(pd.read_csv(\"data/diabetes/Y_val.csv\", header=None)).reshape(-1).astype(int)\n",
    "Y_test = np.asarray(pd.read_csv(\"data/diabetes/Y_test.csv\", header=None)).reshape(-1).astype(int)\n",
    "header = pd.read_csv(\"data/diabetes/diab_train.csv\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_pca_max\n",
    "X_val = X_val_pca_max\n",
    "X_test = X_test_pca_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.vstack([X, X_val])\n",
    "Y2 = np.hstack([Y, Y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'payer_code', 'medical_specialty', 'num_lab_procedures',\n",
      "       'num_procedures', 'num_medications', 'number_outpatient',\n",
      "       'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3',\n",
      "       'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin',\n",
      "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
      "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide.metformin', 'glipizide.metformin',\n",
      "       'glimepiride.pioglitazone', 'metformin.rosiglitazone',\n",
      "       'metformin.pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'diag_1_desc', 'diag_2_desc', 'diag_3_desc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    x = Input(shape=(65,))\n",
    "    x_d = Input(shape=(10, 3174))\n",
    "    x_dis = Input(shape=(4, 44))\n",
    "    \n",
    "    rnn_d = LSTM(30)(x_d)\n",
    "    rnn_dis = LSTM(20)(x_dis)\n",
    "    \n",
    "    conc = Concatenate()([x, rnn_d, rnn_dis])\n",
    "\n",
    "    dense = Dense(400, activation='relu', name=\"dense\")(x)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(300, activation='relu', name=\"dense2\")(dense)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(200, activation='relu', name=\"dense3\")(dense)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(100, activation='relu', name=\"dense4\")(dense)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    y = Dense(1, activation='sigmoid', name=\"y\")(dense)\n",
    "\n",
    "    model = models.Model([x, x_d, x_dis], y, name=\"model\")\n",
    "    model.compile(optimizer='Adam', loss=\"binary_crossentropy\", metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400)          26400       input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 400)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400)          1600        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 300)          120300      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 300)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 300)          1200        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 200)          60200       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 200)          0           dense3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 200)          800         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense4 (Dense)                  (None, 100)          20100       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 100)          0           dense4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 100)          400         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 10, 3174)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 4, 44)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            101         batch_normalization_15[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 231,101\n",
      "Trainable params: 229,101\n",
      "Non-trainable params: 2,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[0.03523807, 0.        , 0.08222217, ..., 0.        , 0.        ,\n        0.        ],\n       [0.03279521, 0.        , 0.05465868, ..., 0.        , 0.        ,\n        0.        ],\n       [0.0...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-942f15af6341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m m.fit([X, X_diagnoses, X_discharge_disposition], Y, shuffle=True, epochs=100, \\\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       callbacks=cbs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                     \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m                                     distribution_strategy=distribution_strategy)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       raise ValueError('`validation_steps` should not be specified if '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    529\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[0.03523807, 0.        , 0.08222217, ..., 0.        , 0.        ,\n        0.        ],\n       [0.03279521, 0.        , 0.05465868, ..., 0.        , 0.        ,\n        0.        ],\n       [0.0..."
     ]
    }
   ],
   "source": [
    "cbs = []\n",
    "cbs.append(EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1))\n",
    "cbs.append(ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2))        \n",
    "m.fit([X, X_diagnoses, X_discharge_disposition], Y, shuffle=True, epochs=100, \\\n",
    "      validation_data=([X_val], Y_val), \\\n",
    "      callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4016326530612245"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, m.predict(X_val).round().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1]\n",
      "[0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(m.predict(X_val).round().astype(int).reshape(-1)[:30])\n",
    "print(Y_val.astype(int).reshape(-1)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'num_leaves': [15, 20, 23, 25, 30, 40, 80],\n",
    "    'reg_alpha': [0.5, 0.7, 0.9, 1.1, 1.3, 1.6],\n",
    "    'min_data_in_leaf': [15, 19, 22, 26, 30, 35, 45, 80],\n",
    "    'max_bin': [150, 200, 250, 300, 350, 400, 450],\n",
    "    'feature_fraction': [.2, .3, .4, .6, .8]\n",
    "    }\n",
    "\n",
    "lgb_estimator = lgbm.LGBMClassifier(objective='binary', \n",
    "                                    class_weight='balanced',\n",
    "                                    eval_metric='f1',\n",
    "                                    jobs=-1)\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X2, y=Y2)\n",
    "gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 23520 candidates, totalling 117600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8176 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9232 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11536 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14096 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 15472 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 16912 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18416 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 21616 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed: 32.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25072 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done 26896 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=-1)]: Done 30736 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=-1)]: Done 32752 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=-1)]: Done 34832 tasks      | elapsed: 54.7min\n",
      "[Parallel(n_jobs=-1)]: Done 36976 tasks      | elapsed: 58.8min\n",
      "[Parallel(n_jobs=-1)]: Done 39184 tasks      | elapsed: 63.6min\n",
      "[Parallel(n_jobs=-1)]: Done 41456 tasks      | elapsed: 69.6min\n",
      "[Parallel(n_jobs=-1)]: Done 43792 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=-1)]: Done 46192 tasks      | elapsed: 85.2min\n",
      "[Parallel(n_jobs=-1)]: Done 48656 tasks      | elapsed: 91.7min\n",
      "[Parallel(n_jobs=-1)]: Done 51184 tasks      | elapsed: 98.8min\n",
      "[Parallel(n_jobs=-1)]: Done 53776 tasks      | elapsed: 107.6min\n",
      "[Parallel(n_jobs=-1)]: Done 56432 tasks      | elapsed: 118.7min\n",
      "[Parallel(n_jobs=-1)]: Done 59152 tasks      | elapsed: 130.3min\n",
      "[Parallel(n_jobs=-1)]: Done 61936 tasks      | elapsed: 134.7min\n",
      "[Parallel(n_jobs=-1)]: Done 64784 tasks      | elapsed: 139.6min\n",
      "[Parallel(n_jobs=-1)]: Done 67696 tasks      | elapsed: 145.2min\n",
      "[Parallel(n_jobs=-1)]: Done 70672 tasks      | elapsed: 151.2min\n",
      "[Parallel(n_jobs=-1)]: Done 73712 tasks      | elapsed: 156.9min\n",
      "[Parallel(n_jobs=-1)]: Done 76816 tasks      | elapsed: 163.6min\n",
      "[Parallel(n_jobs=-1)]: Done 79984 tasks      | elapsed: 171.4min\n",
      "[Parallel(n_jobs=-1)]: Done 83216 tasks      | elapsed: 179.4min\n",
      "[Parallel(n_jobs=-1)]: Done 86512 tasks      | elapsed: 186.9min\n",
      "[Parallel(n_jobs=-1)]: Done 89872 tasks      | elapsed: 196.0min\n",
      "[Parallel(n_jobs=-1)]: Done 93296 tasks      | elapsed: 206.8min\n",
      "[Parallel(n_jobs=-1)]: Done 96784 tasks      | elapsed: 216.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100336 tasks      | elapsed: 228.2min\n",
      "[Parallel(n_jobs=-1)]: Done 103952 tasks      | elapsed: 242.9min\n"
     ]
    }
   ],
   "source": [
    "lgb_model = gsearch.fit(X=X2, y=Y2)\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vescovo/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=1.0, feature_fraction=0.26,\n",
       "               importance_type='split', learning_rate=0.1, max_bin=280,\n",
       "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_data_in_leaf=30, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_boost_round=1000, num_leaves=21,\n",
       "               objective='binary', random_state=None, reg_alpha=1.3,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_estimator = lgbm.LGBMClassifier(boosting_type='gbdt', \n",
    "                                    min_data_in_leaf=30, \\\n",
    "                                    num_leaves=21, \n",
    "                                    max_bin=280, \n",
    "                                    reg_alpha=1.3,\n",
    "                                    objective='binary', \\\n",
    "                                    class_weight='balanced',\n",
    "                                    feature_fraction=.26,\n",
    "                                    num_boost_round=1000\n",
    "                                   )\n",
    "lgb_estimator.fit(np.vstack([X, X_val]),\n",
    "                  np.hstack([Y, Y_val]),\n",
    "                  eval_set=(X_val, Y_val), \n",
    "                  early_stopping_rounds=5, \n",
    "                  eval_metric='f1', verbose=0, \n",
    "                  callbacks = [lgbm.reset_parameter(learning_rate = np.linspace(0.12, 0.05, 20).tolist()+[0.05]*980)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5446371226718048\n",
      "[1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1]\n",
      "[6 7 8 7 8 7 5 8 5 5 8 6 5 9 7 5 7 8 7 6 6 6 6 7 7 8 5 5 9 6]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(Y_test, lgb_estimator.predict(X_test).round().astype(int)))\n",
    "print(lgb_estimator.predict(X_test)[:30])\n",
    "print((np.round(np.max(lgb_estimator.predict_proba(X_test)[:30], axis=1), 1)*10).astype(int))\n",
    "print(Y_test[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 90],\n",
       "       [ 5, 60],\n",
       "       [ 5, 78],\n",
       "       [ 5, 48],\n",
       "       [ 5, 21],\n",
       "       [ 5, 94],\n",
       "       [ 6, 66],\n",
       "       [ 6, 72],\n",
       "       [ 7, 88],\n",
       "       [ 7, 92],\n",
       "       [ 8, 86],\n",
       "       [ 8, 76],\n",
       "       [ 8, 22],\n",
       "       [ 9, 68],\n",
       "       [ 9, 91],\n",
       "       [10, 81],\n",
       "       [10, 75],\n",
       "       [10, 45],\n",
       "       [11, 80],\n",
       "       [11, 87],\n",
       "       [14, 65],\n",
       "       [15, 89],\n",
       "       [15, 93],\n",
       "       [15,  7],\n",
       "       [15, 69],\n",
       "       [17, 96],\n",
       "       [17, 24],\n",
       "       [17, 85],\n",
       "       [17, 13],\n",
       "       [18, 79],\n",
       "       [18, 44],\n",
       "       [18, 82],\n",
       "       [18, 73],\n",
       "       [20, 14],\n",
       "       [20, 38],\n",
       "       [22, 74],\n",
       "       [22, 39],\n",
       "       [22,  1],\n",
       "       [23,  3],\n",
       "       [24, 84],\n",
       "       [25, 10],\n",
       "       [26, 70],\n",
       "       [26, 62],\n",
       "       [26,  5],\n",
       "       [29, 83],\n",
       "       [33, 32],\n",
       "       [33, 71],\n",
       "       [35, 77],\n",
       "       [36,  6],\n",
       "       [36,  9],\n",
       "       [38,  2],\n",
       "       [39, 54],\n",
       "       [39, 42],\n",
       "       [42, 97],\n",
       "       [46,  4],\n",
       "       [46, 95],\n",
       "       [52,  0],\n",
       "       [65, 12],\n",
       "       [66,  8],\n",
       "       [68, 11]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(list(zip(np.sort(lgb_estimator.feature_importances_), np.argsort(lgb_estimator.feature_importances_))))[-60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [30, 35, 40, 45, 50],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    #'degree': [2, 3, 4, 5],\n",
    "    'gamma': ['auto'],\n",
    "    'shrinking': [True],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "\n",
    "clf = SVC(class_weight='balanced')\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X2, y=Y2)\n",
    "gsearch_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   30.7s\n",
      "/home/vescovo/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'decision_function_shape': 'ovo', 'gamma': 'auto', 'kernel': 'linear', 'shrinking': True} 0.5315334168897159\n"
     ]
    }
   ],
   "source": [
    "clf_model = gsearch_clf.fit(X=X2, y=Y2)\n",
    "print(clf_model.best_params_, clf_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(class_weight='balanced', C=100, kernel='linear', degree=2, gamma='auto', shrinking=True, decision_function_shape='ovo')\n",
    "clf.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46586910626319494"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, clf.predict(X_test).round().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1, 2],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4, 5],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'shrinking': [True, False],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X2, y=Y2)\n",
    "gsearch_ada = GridSearchCV(estimator=ada, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 512 candidates, totalling 2560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter C for estimator AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n                   n_estimators=1000, random_state=0). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/vescovo/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/vescovo/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/vescovo/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/vescovo/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/vescovo/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/vescovo/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 504, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/home/vescovo/anaconda3/lib/python3.7/site-packages/sklearn/base.py\", line 236, in set_params\n    (key, self))\nValueError: Invalid parameter C for estimator AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n                   n_estimators=1000, random_state=0). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-7cbe18bf17f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mada_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsearch_ada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mada_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    689\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 691\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter C for estimator AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n                   n_estimators=1000, random_state=0). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "ada_model = gsearch_ada.fit(X=X2, y=Y2)\n",
    "print(ada_model.best_params_, ada_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "ada.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4201930215293245"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, ada.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 4, 5, 6, 10, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "\n",
    "knn = KNeighborsClassifier(4, weights='distance')\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X2, y=Y2)\n",
    "gsearch_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   18.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} 0.4299845194601132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   29.2s finished\n"
     ]
    }
   ],
   "source": [
    "knn_model = gsearch_knn.fit(X=X2, y=Y2)\n",
    "print(knn_model.best_params_, knn_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(3, weights='distance')\n",
    "knn.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4078431372549019"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = GaussianProcessClassifier(kernel=kernel, random_state=0, n_jobs=-1).fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39530988274706874"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, gpc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(n_jobs=-1)\n",
    "dt = dt.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4542079207920792"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
