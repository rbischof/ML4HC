{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c57e3305d030>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMasking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Masking, Bidirectional, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTSNE(tsne_results, Y_test):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    label = Y_test\n",
    "    colors = ['blue', 'red']\n",
    "    plt.scatter(x=tsne_results[:,0], y=tsne_results[:,1], c=label, cmap=matplotlib.colors.ListedColormap(colors), s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_mean = np.asarray(pd.read_csv(\"data/diabetes/X_pca_mean.csv\", header=None))[:6000]\n",
    "X_val_pca_mean = np.asarray(pd.read_csv(\"data/diabetes/X_pca_mean.csv\", header=None))[6000:8000]\n",
    "X_test_pca_mean = np.asarray(pd.read_csv(\"data/diabetes/X_pca_mean.csv\", header=None))[8000:]\n",
    "\n",
    "X_lda_mean = np.asarray(pd.read_csv(\"data/diabetes/X_lda_mean.csv\", header=None))[:6000]\n",
    "X_val_lda_mean = np.asarray(pd.read_csv(\"data/diabetes/X_lda_mean.csv\", header=None))[6000:8000]\n",
    "X_test_lda_mean = np.asarray(pd.read_csv(\"data/diabetes/X_lda_mean.csv\", header=None))[8000:]\n",
    "\n",
    "X_pca_max = np.asarray(pd.read_csv(\"data/diabetes/X_pca_max.csv\", header=None))[:6000]\n",
    "X_val_pca_max = np.asarray(pd.read_csv(\"data/diabetes/X_pca_max.csv\", header=None))[6000:8000]\n",
    "X_test_pca_max = np.asarray(pd.read_csv(\"data/diabetes/X_pca_max.csv\", header=None))[8000:]\n",
    "\n",
    "X_lda_max = np.asarray(pd.read_csv(\"data/diabetes/X_lda_max.csv\", header=None))[:6000]\n",
    "X_val_lda_max = np.asarray(pd.read_csv(\"data/diabetes/X_lda_max.csv\", header=None))[6000:8000]\n",
    "X_test_lda_max = np.asarray(pd.read_csv(\"data/diabetes/X_lda_max.csv\", header=None))[8000:]\n",
    "\n",
    "X_pca_conc = np.asarray(pd.read_csv(\"data/diabetes/X_pca_conc.csv\", header=None))[:6000]\n",
    "X_val_pca_conc = np.asarray(pd.read_csv(\"data/diabetes/X_pca_conc.csv\", header=None))[6000:8000]\n",
    "X_test_pca_conc = np.asarray(pd.read_csv(\"data/diabetes/X_pca_conc.csv\", header=None))[8000:]\n",
    "\n",
    "X_lda_conc = np.asarray(pd.read_csv(\"data/diabetes/X_lda_conc.csv\", header=None))[:6000]\n",
    "X_val_lda_conc = np.asarray(pd.read_csv(\"data/diabetes/X_lda_conc.csv\", header=None))[6000:8000]\n",
    "X_test_lda_conc = np.asarray(pd.read_csv(\"data/diabetes/X_lda_conc.csv\", header=None))[8000:]\n",
    "\n",
    "Y = np.asarray(pd.read_csv(\"data/diabetes/Y.csv\", header=None)).reshape(-1).astype(int)\n",
    "Y_val = np.asarray(pd.read_csv(\"data/diabetes/Y_val.csv\", header=None)).reshape(-1).astype(int)\n",
    "Y_test = np.asarray(pd.read_csv(\"data/diabetes/Y_test.csv\", header=None)).reshape(-1).astype(int)\n",
    "header = pd.read_csv(\"data/diabetes/diab_train.csv\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_pca_mean\n",
    "X_val = X_val_pca_mean\n",
    "X_test = X_test_pca_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'payer_code', 'medical_specialty', 'num_lab_procedures',\n",
      "       'num_procedures', 'num_medications', 'number_outpatient',\n",
      "       'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3',\n",
      "       'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin',\n",
      "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
      "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide.metformin', 'glipizide.metformin',\n",
      "       'glimepiride.pioglitazone', 'metformin.rosiglitazone',\n",
      "       'metformin.pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'diag_1_desc', 'diag_2_desc', 'diag_3_desc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    x = Input(shape=(65,))\n",
    "    x_d = Input(shape=(10, 3174))\n",
    "    x_dis = Input(shape=(4, 44))\n",
    "    \n",
    "    rnn_d = LSTM(30)(x_d)\n",
    "    rnn_dis = LSTM(20)(x_dis)\n",
    "    \n",
    "    conc = Concatenate()([x, rnn_d, rnn_dis])\n",
    "\n",
    "    dense = Dense(400, activation='relu', name=\"dense\")(x)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(300, activation='relu', name=\"dense2\")(dense)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(200, activation='relu', name=\"dense3\")(dense)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(100, activation='relu', name=\"dense4\")(dense)\n",
    "    dense = Dropout(.1)(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    y = Dense(1, activation='sigmoid', name=\"y\")(dense)\n",
    "\n",
    "    model = models.Model([x, x_d, x_dis], y, name=\"model\")\n",
    "    model.compile(optimizer='Adam', loss=\"binary_crossentropy\", metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400)          26400       input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 400)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 400)          1600        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 300)          120300      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 300)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 300)          1200        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 200)          60200       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 200)          0           dense3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 200)          800         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense4 (Dense)                  (None, 100)          20100       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 100)          0           dense4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 100)          400         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 10, 3174)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 4, 44)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            101         batch_normalization_15[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 231,101\n",
      "Trainable params: 229,101\n",
      "Non-trainable params: 2,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[0.03523807, 0.        , 0.08222217, ..., 0.        , 0.        ,\n        0.        ],\n       [0.03279521, 0.        , 0.05465868, ..., 0.        , 0.        ,\n        0.        ],\n       [0.0...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-942f15af6341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m m.fit([X, X_diagnoses, X_discharge_disposition], Y, shuffle=True, epochs=100, \\\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       callbacks=cbs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                     \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m                                     distribution_strategy=distribution_strategy)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       raise ValueError('`validation_steps` should not be specified if '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    529\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[0.03523807, 0.        , 0.08222217, ..., 0.        , 0.        ,\n        0.        ],\n       [0.03279521, 0.        , 0.05465868, ..., 0.        , 0.        ,\n        0.        ],\n       [0.0..."
     ]
    }
   ],
   "source": [
    "cbs = []\n",
    "cbs.append(EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1))\n",
    "cbs.append(ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2))        \n",
    "m.fit([X, X_diagnoses, X_discharge_disposition], Y, shuffle=True, epochs=100, \\\n",
    "      validation_data=([X_val], Y_val), \\\n",
    "      callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4016326530612245"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, m.predict(X_val).round().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1]\n",
      "[0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(m.predict(X_val).round().astype(int).reshape(-1)[:30])\n",
    "print(Y_val.astype(int).reshape(-1)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'num_leaves': [18, 22, 25],\n",
    "    'reg_alpha': [0.5, 0.8, 1],\n",
    "    'min_data_in_leaf': [80, 110, 130],\n",
    "    'max_bin': [200, 258, 300, 500],\n",
    "    'feature_fraction': [.3, .5, .8],\n",
    "    'bagging_fraction': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "lgb_estimator = lgbm.LGBMClassifier(objective='binary', \n",
    "                                    class_weight='balanced',\n",
    "                                    eval_metric='f1',\n",
    "                                    jobs=-1)\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X, y=Y)\n",
    "gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed: 10.7min\n"
     ]
    }
   ],
   "source": [
    "lgb_model = gsearch.fit(X=X, y=Y)\n",
    "print(lgb_model.best_params_, lgb_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vescovo/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/vescovo/anaconda3/lib/python3.7/site-packages/lightgbm/callback.py:192: UserWarning: Early stopping is not available in dart mode\n",
      "  warnings.warn('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight='balanced',\n",
       "               colsample_bytree=1.0, feature_fraction=0.6,\n",
       "               importance_type='split', lambda_l1=1, lambda_l2=0,\n",
       "               learning_rate=0.1, max_bin=258, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001,\n",
       "               min_data_in_leaf=110, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_boost_round=1000, num_leaves=18,\n",
       "               objective='binary', random_state=None, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_estimator = lgbm.LGBMClassifier(boosting_type='gbdt', \\\n",
    "                                    lambda_l1=1, \\\n",
    "                                    lambda_l2=0, \\\n",
    "                                    min_data_in_leaf=110, \\\n",
    "                                    num_leaves=18, \n",
    "                                    max_bin=258, \\\n",
    "                                    objective='binary', \\\n",
    "                                    class_weight='balanced',\n",
    "                                    feature_fraction=.6,\n",
    "                                    num_boost_round=1000\n",
    "                                   )\n",
    "lgb_estimator.fit(X_pca_mean,\n",
    "                  Y,\n",
    "                  eval_set=(X_val, Y_val), \n",
    "                  early_stopping_rounds=5, \n",
    "                  eval_metric='f1', verbose=0, \n",
    "                  callbacks = [lgbm.reset_parameter(learning_rate = np.linspace(0.12, 0.05, 20).tolist()+[0.05]*980)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5579450418160095\n",
      "[1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1]\n",
      "[5 5 7 7 7 7 7 7 5 6 7 5 6 7 7 6 7 6 6 7 6 5 5 6 6 7 5 7 7 6]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(Y_test, lgb_estimator.predict(X_test).round().astype(int)))\n",
    "print(lgb_estimator.predict(X_test)[:30])\n",
    "print((np.round(np.max(lgb_estimator.predict_proba(X_test)[:30], axis=1), 1)*10).astype(int))\n",
    "print(Y_test[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 90],\n",
       "       [ 5, 60],\n",
       "       [ 5, 78],\n",
       "       [ 5, 48],\n",
       "       [ 5, 21],\n",
       "       [ 5, 94],\n",
       "       [ 6, 66],\n",
       "       [ 6, 72],\n",
       "       [ 7, 88],\n",
       "       [ 7, 92],\n",
       "       [ 8, 86],\n",
       "       [ 8, 76],\n",
       "       [ 8, 22],\n",
       "       [ 9, 68],\n",
       "       [ 9, 91],\n",
       "       [10, 81],\n",
       "       [10, 75],\n",
       "       [10, 45],\n",
       "       [11, 80],\n",
       "       [11, 87],\n",
       "       [14, 65],\n",
       "       [15, 89],\n",
       "       [15, 93],\n",
       "       [15,  7],\n",
       "       [15, 69],\n",
       "       [17, 96],\n",
       "       [17, 24],\n",
       "       [17, 85],\n",
       "       [17, 13],\n",
       "       [18, 79],\n",
       "       [18, 44],\n",
       "       [18, 82],\n",
       "       [18, 73],\n",
       "       [20, 14],\n",
       "       [20, 38],\n",
       "       [22, 74],\n",
       "       [22, 39],\n",
       "       [22,  1],\n",
       "       [23,  3],\n",
       "       [24, 84],\n",
       "       [25, 10],\n",
       "       [26, 70],\n",
       "       [26, 62],\n",
       "       [26,  5],\n",
       "       [29, 83],\n",
       "       [33, 32],\n",
       "       [33, 71],\n",
       "       [35, 77],\n",
       "       [36,  6],\n",
       "       [36,  9],\n",
       "       [38,  2],\n",
       "       [39, 54],\n",
       "       [39, 42],\n",
       "       [42, 97],\n",
       "       [46,  4],\n",
       "       [46, 95],\n",
       "       [52,  0],\n",
       "       [65, 12],\n",
       "       [66,  8],\n",
       "       [68, 11]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(list(zip(np.sort(lgb_estimator.feature_importances_), np.argsort(lgb_estimator.feature_importances_))))[-60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [30, 35, 40, 45, 50],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    #'degree': [2, 3, 4, 5],\n",
    "    'gamma': ['auto'],\n",
    "    'shrinking': [True],\n",
    "    'decision_function_shape': ['ovo']\n",
    "    }\n",
    "\n",
    "clf = SVC(class_weight='balanced')\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X2, y=Y2)\n",
    "gsearch_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 40, 'decision_function_shape': 'ovo', 'gamma': 'auto', 'kernel': 'linear', 'shrinking': True} 0.5613633484713509\n"
     ]
    }
   ],
   "source": [
    "clf_model = gsearch_clf.fit(X=X2, y=Y2)\n",
    "print(clf_model.best_params_, clf_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=40, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(class_weight='balanced', C=40, kernel='linear', degree=2, gamma='auto', shrinking=True, decision_function_shape='ovo')\n",
    "clf.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5635738831615119"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, clf.predict(X_test_comb).round().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1, 2],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4, 5],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'shrinking': [True, False],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X_comb, y=Y)\n",
    "gsearch_ada = GridSearchCV(estimator=ada, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = gsearch_ada.fit(X=X_comb, y=Y)\n",
    "print(ada_model.best_params_, ada_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "ada.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4201930215293245"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, ada.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', \n",
    "             'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.00001, 1e-06, 1e-07],\n",
    "    'l1_ratio': [0.2, 0.3, 0.6, 1],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [.2]\n",
    "    }\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X2, y=Y2)\n",
    "gsearch_sgd = GridSearchCV(estimator=sgd, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 944 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1520 tasks      | elapsed:   19.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-06, 'early_stopping': True, 'l1_ratio': 1, 'loss': 'epsilon_insensitive', 'penalty': 'l2', 'validation_fraction': 0.2} 0.5607605480723965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:   20.6s finished\n"
     ]
    }
   ],
   "source": [
    "sgd_model = gsearch_sgd.fit(X=X2, y=Y2)\n",
    "print(sgd_model.best_params_, sgd_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=100, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss=\"log\", alpha=1e-05, early_stopping=True, l1_ratio=.3, penalty=\"l2\", max_iter=100)\n",
    "sgd.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010012515644555695"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, sgd.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007537688442211054"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, sgd.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.predict(X_val).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 4, 5, 6, 10, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30, 40],\n",
    "    'early_stopping': [True, False],\n",
    "    'validation_fraction': [.2]\n",
    "    }\n",
    "\n",
    "knn = KNeighborsClassifier(4, weights='distance')\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X_comb, y=Y)\n",
    "gsearch_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv=gkf, verbose=3, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = gsearch_knn.fit(X=X_comb, y=Y)\n",
    "print(knn_model.best_params_, knn_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(4, weights='distance')\n",
    "knn.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42946490618485056"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, knn.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = GaussianProcessClassifier(kernel=kernel, random_state=0).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37823834196891193"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, gpc.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4616360177552315"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_val, dt.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
